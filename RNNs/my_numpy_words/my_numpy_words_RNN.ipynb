{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Steps\n",
    "# - Initialize weights randomly\n",
    "#     - Uniform Distribution Instantiation\n",
    "#     - Xavier Instantiation\n",
    "# - Give the model input and targets char pairs \n",
    "# - Forward pass \n",
    "#     - Calculate the probability for every possible \n",
    "#           next char according to the state of the model\n",
    "# - Measure error\n",
    "#     - Multi-Class Deviance\n",
    "#     - Support \n",
    "# - Backpropagation Through Time\n",
    "# - Update all parameters \n",
    "#     - Adagrad\n",
    "#     - AdaDelta\n",
    "# - Repeat Until Converged or Stops Improving\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Words: 25061\n",
      "Number of Unique Words: 4565\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "data = open('kafka.txt','r').read()\n",
    "\n",
    "#Remove `\\n` & tokenize by ' '\n",
    "data = data.replace('\\n',' ')\n",
    "total_word_count = len(data.split())\n",
    "word_basis = list(set(data.split()))\n",
    "word_count = len(word_basis)\n",
    "\n",
    "#Convert data into list of strings\n",
    "data = data.split()\n",
    "\n",
    "print('Total Number of Words: %s' % (total_word_count))\n",
    "print('Number of Unique Words: %s' % (len(word_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping Dictionaries\n",
    "word_to_ix = {word:i for i,word in enumerate(word_basis)}\n",
    "ix_to_word = {i:word for i,word in enumerate(word_basis)}\n",
    "\n",
    "#print word_to_ix\n",
    "#print ix_to_word\n",
    "\n",
    "# vector_for_word_a = np.zeros((word_count,1))\n",
    "# vector_for_word_a[word_to_ix['ever']]=1\n",
    "# print word_to_ix['ever']\n",
    "# print vector_for_word_a.ravel()[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Parameters\n",
    "h1_size = 200\n",
    "h2_size = 200\n",
    "seq_len = 6\n",
    "\n",
    "#Hyperparameter\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight and Bias Initialization\n",
    "\n",
    "#Uniform Distribution\n",
    "Wxh = np.random.randn(h1_size,word_count)*0.01\n",
    "Whh = np.random.randn(h1_size, h2_size) * 0.01 #input to hidden\n",
    "Why = np.random.randn(word_count, h2_size) * 0.01 #input to hidden\n",
    "bh = np.zeros((h1_size, 1))\n",
    "by = np.zeros((word_count, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFun(inputs,targets,hprev):\n",
    "    xs, hs, ys, ps, = {}, {}, {}, {} #Empty dicts\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    #forward pass\n",
    "    for t in xrange(len(inputs)):\n",
    "        xs[t] = np.zeros((word_count,1)) # encode in 1-of-k representation (we place a 0 vector as the t-th input)                                                                                                                     \n",
    "        xs[t][inputs[t]] = 1 # Inside that t-th input we use the integer in \"inputs\" list to  set the correct\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state                                                                                                            \n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars                                                                                                           \n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars                                                                                                              \n",
    "        loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)                                                                                                                       \n",
    "    \n",
    "    #backward pass\n",
    "    #initialize vectors for gradient values of weights\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    \n",
    "    for t in reversed(xrange(len(inputs))):\n",
    "        #output probabilities\n",
    "        dy = np.copy(ps[t])\n",
    "        \n",
    "        #derive our first gradient\n",
    "        dy[targets[t]] -= 1 # backprop into y  \n",
    "        \n",
    "        #Compute output gradient -  output times hidden states transpose\n",
    "        #  When we apply the transpose weight matrix,  \n",
    "        #  we can think intuitively of this as moving the error backward\n",
    "        #  through the network, giving us some sort of measure of the error \n",
    "        #  at the output of the lth layer. \n",
    "        \n",
    "        #output gradient\n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        \n",
    "        #derivative of output bias\n",
    "        dby += dy\n",
    "        \n",
    "        #backpropagate!\n",
    "        dh = np.dot(Why.T, dy) + dhnext # backprop into h                                                                                                                                         \n",
    "        \n",
    "        # backprop through tanh nonlinearity \n",
    "        #     - revisit activation function in future\n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh \n",
    "        dbh += dhraw #derivative of hidden bias\n",
    "        dWxh += np.dot(dhraw, xs[t].T) #derivative of input to hidden layer weight\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T) #derivative of hidden layer to hidden layer weight\n",
    "        dhnext = np.dot(Whh.T, dhraw) \n",
    "\n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients                                                                                                                 \n",
    "    \n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " ['\"What', 'outstretched,', 'here!', 'drawers.'] \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#prediction, one full forward pass\n",
    "def sample(h, seed_ix, n):\n",
    "    \"\"\"                                                                                                                                                                                         \n",
    "    sample a sequence of integers from the model                                                                                                                                                \n",
    "    h is memory state, seed_ix is seed letter for first time step   \n",
    "    n is how many characters to predict\n",
    "    \"\"\"\n",
    "    #create vector\n",
    "    x = np.zeros((word_count, 1))\n",
    "    \n",
    "    #customize it for our seed char\n",
    "    x[seed_ix] = 1\n",
    "    \n",
    "    #list to store generated chars\n",
    "    ixes = []\n",
    "    \n",
    "    #for as many words as we want to generate\n",
    "    for t in xrange(n):\n",
    "        #A hidden state at a given time step is a function \n",
    "        #  of (1) the input at the same time step modified by a weight matrix \n",
    "        #  added to (2) the hidden state of the previous time step \n",
    "        #  multiplied by its own hidden state to hidden state matrix.\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "        \n",
    "        #compute output (unnormalised)\n",
    "        y = np.dot(Why, h) + by\n",
    "        \n",
    "        ## probabilities for next chars\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        \n",
    "        #pick one with the highest probability (not exactly)\n",
    "        #--This implementation is not strictly mathematically correct\n",
    "        #--it allows for random sampling using the probability distribution\n",
    "        #--specified by p. If stochastic sampling is meant to be used\n",
    "        #--as perturbation to prevent overfitting in training, then it is correct.\n",
    "        ix = np.argmax(p.ravel())\n",
    "        \n",
    "        #create a vector\n",
    "        x = np.zeros((word_count, 1))\n",
    "        \n",
    "        #customize it for the predicted word\n",
    "        x[ix] = 1\n",
    "        \n",
    "        #add it to the list\n",
    "        ixes.append(ix)\n",
    "\n",
    "    txt = [ix_to_word[ix] for ix in ixes]\n",
    "    print '----\\n %s \\n----' % (txt, )\n",
    "    \n",
    "# reset RNN memory \n",
    "hprev = np.zeros((h2_size,1)) \n",
    "\n",
    "#predict the next word given 'ever'\n",
    "sample(hprev,word_to_ix['ever'],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 50.557043\n",
      "----\n",
      " ['royalties.', 'current', 'can.', 'at', 'demand', 'been.'] \n",
      "----\n",
      "iter 1000, loss: 75.951483\n",
      "----\n",
      " ['the', 'sister', 'the', 'sister', 'the', 'sister'] \n",
      "----\n",
      "iter 2000, loss: 69.143843\n",
      "----\n",
      " ['the', 'opposite;', 'the', 'opposite;', 'the', 'opposite;'] \n",
      "----\n",
      "iter 3000, loss: 62.644976\n",
      "----\n",
      " ['in', 'movement;', 'in', 'movement;', 'in', 'movement;'] \n",
      "----\n",
      "iter 4000, loss: 63.236665\n",
      "----\n",
      " ['discover', 'a', 'discover', 'a', 'discover', 'a'] \n",
      "----\n",
      "iter 5000, loss: 52.827167\n",
      "----\n",
      " ['chief', 'sounded', 'chief', 'the', 'chief', 'sounded'] \n",
      "----\n",
      "iter 6000, loss: 46.177927\n",
      "----\n",
      " ['the', 'the', 'the', 'he', 'had', 'the'] \n",
      "----\n",
      "iter 7000, loss: 43.678610\n",
      "----\n",
      " ['the', 'learned', 'of', 'learned', 'the', 'learned'] \n",
      "----\n",
      "iter 8000, loss: 43.621594\n",
      "----\n",
      " ['of', 'the', 'Project', 'The', 'Project', 'The'] \n",
      "----\n",
      "iter 9000, loss: 42.511480\n",
      "----\n",
      " ['the', 'train,', \"o'clock\", 'train,', 'the', 'train,'] \n",
      "----\n",
      "iter 10000, loss: 40.721739\n",
      "----\n",
      " ['the', 'the', 'state,', 'of', 'the', 'present'] \n",
      "----\n",
      "iter 11000, loss: 39.888360\n",
      "----\n",
      " ['and', 'the', 'door', 'of', 'the', 'room'] \n",
      "----\n",
      "iter 12000, loss: 39.755962\n",
      "----\n",
      " ['of', 'the', 'door', 'and', 'their', 'seats,'] \n",
      "----\n",
      "iter 13000, loss: 39.484350\n",
      "----\n",
      " ['the', 'chief', 'here.\"', 'and', 'the', 'chief'] \n",
      "----\n",
      "iter 14000, loss: 38.546617\n",
      "----\n",
      " ['had', 'the', 'little', 'and', 'had', 'to'] \n",
      "----\n",
      "iter 15000, loss: 37.713063\n",
      "----\n",
      " ['his', 'sister', 'was', 'the', 'habit', 'of'] \n",
      "----\n",
      "iter 16000, loss: 37.595690\n",
      "----\n",
      " ['the', 'little', 'followed', 'the', 'followed', 'and'] \n",
      "----\n",
      "iter 17000, loss: 38.044179\n",
      "----\n",
      " ['he', 'was', 'not', 'the', 'bulk', 'of'] \n",
      "----\n",
      "iter 18000, loss: 36.892174\n",
      "----\n",
      " ['was', 'the', 'door,', 'of', 'the', 'door'] \n",
      "----\n",
      "iter 19000, loss: 35.974677\n",
      "----\n",
      " ['the', 'door', 'of', 'the', 'women', 'to'] \n",
      "----\n",
      "iter 20000, loss: 35.999484\n",
      "----\n",
      " ['he', 'could', 'not', 'have', 'to', 'the'] \n",
      "----\n",
      "iter 21000, loss: 36.490747\n",
      "----\n",
      " ['to', 'the', 'boss', 'of', 'the', 'train'] \n",
      "----\n",
      "iter 22000, loss: 35.668705\n",
      "----\n",
      " ['the', 'table', 'and', 'the', 'door', 'of'] \n",
      "----\n",
      "iter 23000, loss: 34.745923\n",
      "----\n",
      " ['to', 'the', 'room', 'and', 'the', 'chest'] \n",
      "----\n",
      "iter 24000, loss: 34.474280\n",
      "----\n",
      " ['playing', 'was', 'their', 'room', 'and', 'the'] \n",
      "----\n",
      "iter 25000, loss: 34.731450\n",
      "----\n",
      " ['and', '($1', 'to', '$5,000)', 'outdated', '($1'] \n",
      "----\n",
      "iter 26000, loss: 34.726541\n",
      "----\n",
      " ['and', 'the', 'chief', 'clerk', 'than', 'the'] \n",
      "----\n",
      "iter 27000, loss: 33.625318\n",
      "----\n",
      " ['the', 'door', 'of', 'the', 'new', 'and'] \n",
      "----\n",
      "iter 28000, loss: 33.337828\n",
      "----\n",
      " ['his', 'room', 'and', 'the', 'family', 'to'] \n",
      "----\n",
      "iter 29000, loss: 33.171407\n",
      "----\n",
      " ['in', 'a', 'full', 'refund', 'of', 'the'] \n",
      "----\n",
      "iter 30000, loss: 33.449624\n",
      "----\n",
      " ['chief', 'clerk,', 'of', 'the', 'chief', 'clerk'] \n",
      "----\n",
      "iter 31000, loss: 32.721082\n",
      "----\n",
      " ['the', 'window', 'and', 'he', 'had', 'been'] \n",
      "----\n",
      "iter 32000, loss: 32.261466\n",
      "----\n",
      " ['was', 'not', 'to', 'the', 'other', 'and'] \n",
      "----\n",
      "iter 33000, loss: 32.575542\n",
      "----\n",
      " ['terms', 'of', 'the', 'Project', 'Gutenberg-tm', 'electronic'] \n",
      "----\n",
      "iter 34000, loss: 32.452351\n",
      "----\n",
      " ['little', 'of', 'the', 'same', 'way', 'he'] \n",
      "----\n",
      "iter 35000, loss: 31.729165\n",
      "----\n",
      " ['the', 'door', 'of', 'the', 'lock', 'and'] \n",
      "----\n",
      "iter 36000, loss: 31.342613\n",
      "----\n",
      " ['to', 'the', 'room', 'and', 'his', 'sister'] \n",
      "----\n",
      "iter 37000, loss: 31.321223\n",
      "----\n",
      " ['the', 'cleaner', 'and', 'had', 'been', 'a'] \n",
      "----\n",
      "iter 38000, loss: 31.338692\n",
      "----\n",
      " ['in', 'a', 'moment', 'to', 'the', 'door'] \n",
      "----\n",
      "iter 39000, loss: 30.783718\n",
      "----\n",
      " ['of', 'the', 'other', 'room', 'that', 'he'] \n",
      "----\n",
      "iter 40000, loss: 30.377210\n",
      "----\n",
      " ['the', 'floor,', 'and', 'the', 'time', 'of'] \n",
      "----\n",
      "iter 41000, loss: 30.379668\n",
      "----\n",
      " ['her', 'back', 'in', 'the', 'floor', 'with'] \n",
      "----\n",
      "iter 42000, loss: 30.403308\n",
      "----\n",
      " ['the', 'bed,', 'of', 'the', 'door', 'was'] \n",
      "----\n",
      "iter 43000, loss: 29.934318\n",
      "----\n",
      " ['was', 'not', 'to', 'his', 'room', 'was'] \n",
      "----\n",
      "iter 44000, loss: 29.515078\n",
      "----\n",
      " ['of', 'his', 'room', 'and', 'the', 'door'] \n",
      "----\n",
      "iter 45000, loss: 29.464145\n",
      "----\n",
      " ['endure', 'it', 'was', 'not', 'endure', 'the'] \n",
      "----\n",
      "iter 46000, loss: 29.186603\n",
      "----\n",
      " ['not', 'be', 'to', 'get', 'the', 'Project'] \n",
      "----\n",
      "iter 47000, loss: 29.208070\n",
      "----\n",
      " ['clerk', 'was', 'not', 'be', 'to', 'the'] \n",
      "----\n",
      "iter 48000, loss: 28.602545\n",
      "----\n",
      " ['door', 'and', 'was', 'not', 'not', 'be'] \n",
      "----\n",
      "iter 49000, loss: 28.546777\n",
      "----\n",
      " ['way', 'of', 'the', 'window', 'and', 'he'] \n",
      "----\n",
      "iter 50000, loss: 28.100719\n",
      "----\n",
      " ['to', 'the', 'Project', 'Gutenberg-tm', 'work,', 'in'] \n",
      "----\n",
      "iter 51000, loss: 28.263813\n",
      "----\n",
      " ['he', 'was', 'not', 'have', 'to', 'the'] \n",
      "----\n",
      "iter 52000, loss: 27.816542\n",
      "----\n",
      " ['and', 'it', 'was', 'not', 'have', 'to'] \n",
      "----\n",
      "iter 53000, loss: 27.817962\n",
      "----\n",
      " ['and', 'the', 'gentlemen', 'had', 'rented', 'the'] \n",
      "----\n",
      "iter 54000, loss: 27.371678\n",
      "----\n",
      " ['access', 'to', 'or', 'Project', 'Gutenberg-tm', 'electronic'] \n",
      "----\n",
      "iter 55000, loss: 27.482375\n",
      "----\n",
      " ['away.', 'he', 'was', 'already', 'in', 'the'] \n",
      "----\n",
      "iter 56000, loss: 27.000867\n",
      "----\n",
      " ['-', 'he', 'had', 'been', 'to', 'the'] \n",
      "----\n",
      "iter 57000, loss: 26.932626\n",
      "----\n",
      " ['a', 'longer', 'and', 'sister', 'had', 'been'] \n",
      "----\n",
      "iter 58000, loss: 27.119975\n",
      "----\n",
      " ['Project', 'Gutenberg', 'Literary', 'Archive', 'Foundation', 'may'] \n",
      "----\n",
      "iter 59000, loss: 26.542082\n",
      "----\n",
      " ['the', 'morning', 'and', 'he', 'had', 'been'] \n",
      "----\n",
      "iter 60000, loss: 26.239339\n",
      "----\n",
      " ['the', 'door', 'and', 'he', 'had', 'left'] \n",
      "----\n",
      "iter 61000, loss: 26.179120\n",
      "----\n",
      " ['sleep', 'out', 'of', 'the', 'door', 'and'] \n",
      "----\n",
      "iter 62000, loss: 26.303885\n",
      "----\n",
      " ['At', 'the', 'three', 'gentlemen', 'had', 'been'] \n",
      "----\n",
      "iter 63000, loss: 25.651924\n",
      "----\n",
      " ['the', 'same', 'work', 'And', 'he', 'had'] \n",
      "----\n",
      "iter 64000, loss: 25.379211\n",
      "----\n",
      " ['from', 'a', 'horrible', 'of', 'the', 'door'] \n",
      "----\n",
      "iter 65000, loss: 25.454307\n",
      "----\n",
      " ['longer', 'about', 'the', 'door', 'and', 'he'] \n",
      "----\n",
      "iter 66000, loss: 25.519505\n",
      "----\n",
      " ['had', 'been', 'in', 'the', 'door', 'and'] \n",
      "----\n",
      "iter 67000, loss: 24.718142\n",
      "----\n",
      " ['to', 'get', 'his', 'sister', 'had', 'been'] \n",
      "----\n",
      "iter 68000, loss: 24.771831\n",
      "----\n",
      " ['that', 'he', 'had', 'to', 'his', 'father'] \n",
      "----\n",
      "iter 69000, loss: 24.844446\n",
      "----\n",
      " ['into', 'the', 'living', 'room', 'and', 'sister'] \n",
      "----\n",
      "iter 70000, loss: 24.764766\n",
      "----\n",
      " ['three', 'gentlemen', 'had', 'not', 'to', 'the'] \n",
      "----\n",
      "iter 71000, loss: 23.668135\n",
      "----\n",
      " ['to', 'make', 'the', 'Project', 'Gutenberg', 'Literary'] \n",
      "----\n",
      "iter 72000, loss: 24.158755\n",
      "----\n",
      " ['the', 'chief', 'clerk', 'was', 'not', 'understand'] \n",
      "----\n",
      "iter 73000, loss: 24.141570\n",
      "----\n",
      " ['a', 'little', 'and', 'he', 'had', 'been'] \n",
      "----\n",
      "iter 74000, loss: 24.168042\n",
      "----\n",
      " ['was', 'not', 'to', 'be', 'to', 'the'] \n",
      "----\n",
      "iter 75000, loss: 23.201231\n",
      "----\n",
      " ['or', 'return', 'the', 'medium', 'with', 'the'] \n",
      "----\n",
      "iter 76000, loss: 23.431447\n",
      "----\n",
      " ['the', 'wind.', 'he', 'was', 'no', 'longer'] \n",
      "----\n",
      "iter 77000, loss: 23.383500\n",
      "----\n",
      " ['have', 'to', 'the', 'window', 'the', 'door'] \n",
      "----\n",
      "iter 78000, loss: 23.592112\n",
      "----\n",
      " ['of', 'the', 'door', 'and', 'the', 'work'] \n",
      "----\n",
      "iter 79000, loss: 23.007082\n",
      "----\n",
      " ['accessed,', 'displayed,', 'performed,', 'viewed,', 'copied', 'or'] \n",
      "----\n",
      "iter 80000, loss: 23.478490\n",
      "----\n",
      " ['sister', 'had', 'been', 'able', 'to', 'get'] \n",
      "----\n",
      "iter 81000, loss: 22.995598\n",
      "----\n",
      " ['to', 'be', 'the', 'same', 'room', 'and'] \n",
      "----\n",
      "iter 82000, loss: 23.114423\n",
      "----\n",
      " ['not', 'been', 'forgotten', 'that', 'he', 'had'] \n",
      "----\n",
      "iter 83000, loss: 22.915451\n",
      "----\n",
      " ['good', 'promise', 'for', 'the', 'future.', 'The'] \n",
      "----\n",
      "iter 84000, loss: 22.005686\n",
      "----\n",
      " ['room', 'to', 'the', 'chief', 'clerk', 'is'] \n",
      "----\n",
      "iter 85000, loss: 22.067127\n",
      "----\n",
      " ['sister', 'would', 'have', 'to', 'the', 'couch'] \n",
      "----\n",
      "iter 86000, loss: 22.368607\n",
      "----\n",
      " ['little', 'while', 'Gregor', 'had', 'been', 'to'] \n",
      "----\n",
      "iter 87000, loss: 22.336799\n",
      "----\n",
      " ['The', 'cleaner', 'was', 'in', 'the', 'broom,'] \n",
      "----\n",
      "iter 88000, loss: 21.257570\n",
      "----\n",
      " ['with', 'the', 'lower', 'part', 'of', 'the'] \n",
      "----\n",
      "iter 89000, loss: 21.431517\n",
      "----\n",
      " ['chief', 'clerk', 'was', 'still', 'in', 'the'] \n",
      "----\n",
      "iter 90000, loss: 21.768157\n",
      "----\n",
      " ['had', 'been', 'to', 'the', 'women', 'of'] \n",
      "----\n",
      "iter 91000, loss: 21.686595\n",
      "----\n",
      " ['to', 'the', 'door', 'and', 'the', 'door'] \n",
      "----\n",
      "iter 92000, loss: 20.365034\n",
      "----\n",
      " ['was', 'not', 'a', 'funny', 'sort', 'of'] \n",
      "----\n",
      "iter 93000, loss: 20.768485\n",
      "----\n",
      " ['least', 'that', 'he', 'was', 'not', 'for'] \n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 94000, loss: 21.206807\n",
      "----\n",
      " ['it', 'so', 'that', 'Gregor', 'was', 'not'] \n",
      "----\n",
      "iter 95000, loss: 21.166638\n",
      "----\n",
      " ['sister', 'had', 'been', 'in', 'any', 'room'] \n",
      "----\n",
      "iter 96000, loss: 19.516074\n",
      "----\n",
      " ['works', 'of', 'the', 'United', 'States.', 'Compliance'] \n",
      "----\n",
      "iter 97000, loss: 20.218443\n",
      "----\n",
      " ['and', 'he', 'had', 'been', 'occupied', 'with'] \n",
      "----\n",
      "iter 98000, loss: 20.535725\n",
      "----\n",
      " ['to', 'see', 'it', 'even', 'a', 'great'] \n",
      "----\n",
      "iter 99000, loss: 20.697165\n",
      "----\n",
      " ['the', 'kitchen,', 'as', 'he', 'had', 'been'] \n",
      "----\n",
      "iter 100000, loss: 19.435227\n",
      "----\n",
      " ['comply', 'with', 'the', 'other', 'terms', 'of'] \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#ModelTraining\n",
    "\n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad                                                                                                                \n",
    "smooth_loss = -np.log(1.0/word_count)*seq_len # loss at iteration 0  \n",
    "\n",
    "track_loss = []\n",
    "track_iter = []\n",
    "\n",
    "while n<=1000*100:\n",
    "    # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "    # check \"How to feed the loss function to see how this part works\n",
    "    if p+seq_len+1 >= len(data) or n == 0:\n",
    "        hprev = np.zeros((h2_size,1)) # reset RNN memory                                                                                                                                      \n",
    "        p = 0 # go from start of data  \n",
    "    \n",
    "    # Train on [p:p+seq_len]\n",
    "    # Test on [p+1:p+seq_len+1]\n",
    "    #Predictions are offset from training by 1 word (last target word not in input)\n",
    "    inputs = [word_to_ix[word] for word in data[p:p+seq_len]]\n",
    "    targets = [word_to_ix[word] for word in data[p+1:p+seq_len+1]]\n",
    "\n",
    "    # forward seq_length characters through the net \n",
    "    # and fetch gradient                                                                                                                          \n",
    "    loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "    #store training progress - MIKEY\n",
    "    track_loss.append(loss)\n",
    "    track_iter.append(n)\n",
    "    \n",
    "    # sample from the model now and then                                                                                                                                                        \n",
    "    if n % 1000 == 0:\n",
    "        print 'iter %d, loss: %f' % (n, smooth_loss) # print progress\n",
    "        sample(hprev, inputs[0], seq_len)\n",
    "\n",
    "    # Perform parameter update with Adagrad  -- VERY IMPORTANT                                                                                                                                                   \n",
    "    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
    "                                [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "        mem += dparam * dparam\n",
    "        \n",
    "        #AdaGrad Update\n",
    "        param += -learning_rate * dparam / np.sqrt(mem + 1e-8) \n",
    "\n",
    "    p += seq_len # move data pointer                                                                                                                                                         \n",
    "    n += 1 # iteration counter    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " ['require', 'at', 'the', 'other', 'of', 'the', 'Project', 'Gutenberg-tm', 'works.', '1.E.9.', 'If', 'you', 'may', 'paid', 'at', 'any'] \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#print data[100:100+seq_len]\n",
    "\n",
    "a=[word_to_ix[word] for word in data[30:30+seq_len+10]]\n",
    "#print a\n",
    "sample(hprev, a, seq_len+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10f5b6490>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAGDCAYAAABuj7cYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/Au7qMP9fIxO9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a097610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(track_iter,track_loss)\n",
    "plt.yscale('log')\n",
    "plt.title('Training Loss ')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
